{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GTM mapping\n",
        "- input value : Tf-idf value of doc-term matrix"
      ],
      "metadata": {
        "id": "mF9W24T2s4Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7GX0qH3Kwwu"
      },
      "outputs": [],
      "source": [
        "!pip install ugtm\n",
        "import time\n",
        "from ugtm import eGTM\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "\n",
        "# X value\n",
        "X = tfidf_df.values\n",
        "\n",
        "# GTM fitting\n",
        "start_fit = time.time()\n",
        "gtm_model = eGTM(model='modes').fit(X)\n",
        "end_fit = time.time()\n",
        "\n",
        "# GTM transform\n",
        "start_transform = time.time()\n",
        "coordinates = gtm_model.transform(X)\n",
        "end_transform = time.time()\n",
        "\n",
        "# time\n",
        "print(f\"GTM fitting : {end_fit - start_fit:.2f}초\")\n",
        "print(f\"GTM transform : {end_transform - start_transform:.2f}초\")\n",
        "\n",
        "# to DataFrame\n",
        "df = pd.DataFrame(coordinates, columns=[\"x1\", \"x2\"])\n",
        "\n",
        "# Altair visualization\n",
        "alt.data_transformers.disable_max_rows()\n",
        "chart = alt.Chart(df).mark_point().encode(\n",
        "    x='x1',\n",
        "    y='x2',\n",
        "    tooltip=['x1', 'x2']\n",
        ").properties(\n",
        "    title=\"Technology-Market Vacancy Map\",\n",
        "    width=800,\n",
        "    height=600\n",
        ").interactive()\n",
        "\n",
        "chart"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inverse-mapping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "grid_x, grid_y = np.meshgrid(np.linspace(-1, 1, 16), np.linspace(-1, 1, 16))\n",
        "grid_coords = np.c_[grid_x.ravel(), grid_y.ravel()]\n",
        "\n",
        "occupied_coords = coordinates[:, :2]  # actual coordinates\n",
        "\n",
        "# vacancy : not occupied\n",
        "vacant_coords2 = np.array([\n",
        "    coord for coord in grid_coords\n",
        "    if not any(np.all(coord == occupied_coords, axis=1))\n",
        "])\n",
        "pd.DataFrame(vacant_coords2).to_csv('vacant_coords3.csv', index=False)\n",
        "vc = pd.read_csv('vacant_coords3.csv')\n",
        "vc.shape\n"
      ],
      "metadata": {
        "id": "lVkSEY-gwM6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GTM result coordinates\n",
        "coordinates2 = gtm_model.transform(X)  # (n_docs, 2)\n",
        "\n",
        "# coordinates\n",
        "vacant_coords2 = pd.read_csv(\"vacant_coords3.csv\").to_numpy()  # (n_vacant, 2)\n",
        "\n",
        "# coordinate -> embedding mapping\n",
        "inv_coords = np.linalg.pinv(coordinates2)  # (2, n_docs)\n",
        "inner_embedding = np.matmul(inv_coords, X)  # (2, dim)\n",
        "\n",
        "# pseudo-inverse\n",
        "inv_inner = np.linalg.pinv(inner_embedding.T)  # (2, 384)\n",
        "\n",
        "# vacant coordinates → embedding (inverse)\n",
        "inv_vacant_embeddings2 = np.matmul(vacant_coords2, inv_inner)  # (n_vacant, dim)\n",
        "\n",
        "# result\n",
        "inv_vacant_df2 = pd.DataFrame(inv_vacant_embeddings2, columns=tfidf_df.columns)\n",
        "\n",
        "# add vacant num\n",
        "inv_vacant_df2.insert(0, 'vacant_number', range(len(inv_vacant_df2)))\n",
        "inv_vacant_df2.to_csv(\"inv_mapped_tfidf_from_vacant_coords3.csv\", index=False)\n",
        "inv_vacant_df2.shape"
      ],
      "metadata": {
        "id": "AJRnZl2hwXVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax function\n",
        "- transform to probability distribution"
      ],
      "metadata": {
        "id": "I_psuQZ_xM4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# extract only columns (keywords)\n",
        "keyword_cols = inv_vacant_df2.columns.difference(['vacant_number'])\n",
        "\n",
        "# softmax\n",
        "softmax_values = inv_vacant_df2[keyword_cols].apply(\n",
        "    lambda row: softmax(row.values), axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "# keep column name\n",
        "softmax_values.columns = keyword_cols\n",
        "\n",
        "inv_vacant_prob_df = inv_vacant_df2.copy()\n",
        "inv_vacant_prob_df[keyword_cols] = softmax_values\n",
        "\n",
        "inv_vacant_prob_df.to_csv(\"softmax_vacant_coords2_prob-4.csv\", index=False)"
      ],
      "metadata": {
        "id": "CckCgvIywXYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = pd.read_csv(\"softmax_vacant_coords2_prob-4.csv\")\n",
        "\n",
        "softmax['vacant_number'] = softmax['vacant_number'] + 1\n",
        "\n",
        "softmax = softmax.set_index('vacant_number')\n",
        "\n",
        "softmax.head()"
      ],
      "metadata": {
        "id": "pDYiUC0WwXa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = softmax.sum(axis=1)\n",
        "\n",
        "print(row_sums.describe())\n",
        "\n",
        "#count    5.400000e+01\n",
        "#mean     1.000000e+00\n",
        "#std      1.035884e-15\n",
        "#min      1.000000e+00\n",
        "#25%      1.000000e+00\n",
        "#50%      1.000000e+00\n",
        "#75%      1.000000e+00\n",
        "#max      1.000000e+00"
      ],
      "metadata": {
        "id": "EWWglfJOxWE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set column index (tech, market, overlapping)"
      ],
      "metadata": {
        "id": "h8zPQ2lVx2XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns index\n",
        "keyword_origin_map = {}\n",
        "\n",
        "for kw in combined_top_keywords:\n",
        "    in_patent = kw in patent_top_keywords\n",
        "    in_startup = kw in startup_top_keywords\n",
        "\n",
        "    if in_patent and in_startup:\n",
        "        keyword_origin_map[kw] = 'overlapping'\n",
        "    elif in_patent:\n",
        "        keyword_origin_map[kw] = 'tech'\n",
        "    elif in_startup:\n",
        "        keyword_origin_map[kw] = 'market'\n",
        "    else:\n",
        "        keyword_origin_map[kw] = 'etc'\n",
        "\n",
        "# column level\n",
        "column_sources = [keyword_origin_map.get(kw, 'etc') for kw in softmax.columns]\n",
        "column_keywords = softmax.columns\n",
        "\n",
        "# multi index\n",
        "multi_index = pd.MultiIndex.from_tuples(zip(column_sources, column_keywords))\n",
        "softmax.columns = multi_index"
      ],
      "metadata": {
        "id": "F1vBS-Pvx1Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = softmax.sort_index(axis=1, level=0)\n",
        "\n",
        "# group count\n",
        "keyword_count = softmax.columns.to_series().groupby(level=0).count()\n",
        "\n",
        "print(keyword_count)\n",
        "\n",
        "#market          77\n",
        "#overlapping     47\n",
        "#tech           331"
      ],
      "metadata": {
        "id": "lOoVoUIkyI10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sensitivity analysis of keyword probability\n",
        "- selected by 80% percentile value"
      ],
      "metadata": {
        "id": "8uMvwFV3yXwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_with_quantiles(x):\n",
        "    desc = x.describe()\n",
        "    desc['80%'] = x.quantile(0.80)\n",
        "    desc['85%'] = x.quantile(0.85)\n",
        "    desc['90%'] = x.quantile(0.90)\n",
        "    desc['95%'] = x.quantile(0.95)\n",
        "    return desc\n",
        "\n",
        "row_stats = softmax.apply(describe_with_quantiles, axis=1)\n",
        "display(row_stats)"
      ],
      "metadata": {
        "id": "gF_wPjYlyVMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_keywords_by_quantiles(softmax, row_stats, quantile_cols=('75%', '80%', '85%', '90%', '95%')):\n",
        "    result_rows = []\n",
        "\n",
        "    for vac in softmax.index:\n",
        "        row = softmax.loc[vac]  # vacancy softmax value\n",
        "        row_data = {'vacant_number': vac}\n",
        "\n",
        "        for q in quantile_cols:\n",
        "            threshold = row_stats.loc[vac, q]  # vacancy q% value\n",
        "            count = (row >= threshold).sum()   # over threshold keyword count\n",
        "            # count_ge_75, count_ge_80 ...\n",
        "            col_name = f\"count_ge_{q.replace('%', '')}\"\n",
        "            row_data[col_name] = count\n",
        "\n",
        "        result_rows.append(row_data)\n",
        "\n",
        "    result_df = pd.DataFrame(result_rows).set_index('vacant_number')\n",
        "    return result_df\n",
        "\n",
        "count_table = count_keywords_by_quantiles(\n",
        "    softmax,\n",
        "    row_stats,\n",
        "    quantile_cols=('75%', '80%', '85%', '90%', '95%')\n",
        ")\n",
        "display(count_table)\n",
        "\n",
        "                        #count_ge_75\tcount_ge_80\tcount_ge_85\tcount_ge_90\tcount_ge_95\n",
        "#vacant_number\t\t1\t    114\t         91\t          69\t        46\t        23"
      ],
      "metadata": {
        "id": "VOnBOBksyVQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def build_domain_keyword_value_table(softmax, row_stats, quantile_col='80'):\n",
        "    rows = []\n",
        "\n",
        "    for vac in row_stats.index:\n",
        "        threshold = row_stats.loc[vac, quantile_col]\n",
        "\n",
        "        row = softmax.loc[vac]\n",
        "        selected = row[row >= threshold]\n",
        "\n",
        "        domain_dict = {}\n",
        "\n",
        "        for (domain, keyword), value in selected.items():\n",
        "            entry = f\"{keyword}({value:.6f})\"\n",
        "            if domain not in domain_dict:\n",
        "                domain_dict[domain] = [entry]\n",
        "            else:\n",
        "                domain_dict[domain].append(entry)\n",
        "\n",
        "        for domain in softmax.columns.levels[0]:\n",
        "            domain_dict.setdefault(domain, [])\n",
        "            domain_dict[domain] = \", \".join(domain_dict[domain])\n",
        "\n",
        "        row_data = {'vacancy': vac}\n",
        "        row_data.update(domain_dict)\n",
        "\n",
        "        rows.append(row_data)\n",
        "\n",
        "    final_df = pd.DataFrame(rows)\n",
        "    return final_df\n",
        "\n",
        "build_domain_keyword_value_table(softmax, row_stats, quantile_col='80%')"
      ],
      "metadata": {
        "id": "NE-umD1JyVUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization and visualzation\n",
        "- tech, market, overlapping\n",
        "- in this study, market value was sparse. so we used tech & overlapping index"
      ],
      "metadata": {
        "id": "ZgV2WSIf0P35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overlapping_scores = []\n",
        "tech_scores = []\n",
        "market_scores = []\n",
        "\n",
        "for idx in range(1, 55):\n",
        "    row = softmax.loc[idx]\n",
        "\n",
        "    # N% quantile filtering\n",
        "    threshold = row_stats.loc[idx, '80%']\n",
        "    filtered = row[row >= threshold]\n",
        "\n",
        "    # xs(level=0) sum\n",
        "    overlapping_sum = (\n",
        "        filtered.xs('overlapping', level=0).sum()\n",
        "        if 'overlapping' in filtered.index.get_level_values(0)\n",
        "        else 0\n",
        "    )\n",
        "    tech_sum = (\n",
        "        filtered.xs('tech', level=0).sum()\n",
        "        if 'tech' in filtered.index.get_level_values(0)\n",
        "        else 0\n",
        "    )\n",
        "    market_sum = (\n",
        "        filtered.xs('market', level=0).sum()\n",
        "        if 'market' in filtered.index.get_level_values(0)\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    overlapping_scores.append(overlapping_sum)\n",
        "    tech_scores.append(tech_sum)\n",
        "    market_scores.append(market_sum)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 1) raw DataFrame\n",
        "# -------------------------------------------------------\n",
        "custom_index = [f'V{i}' for i in range(1, 55)]\n",
        "\n",
        "raw_scores = pd.DataFrame({\n",
        "    'overlapping': overlapping_scores,\n",
        "    'tech': tech_scores,\n",
        "    'market': market_scores\n",
        "}, index=custom_index)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 2) standardization (z-score)\n",
        "# -------------------------------------------------------\n",
        "\n",
        "standardized_scores = raw_scores.copy()\n",
        "\n",
        "for col in ['overlapping', 'tech', 'market']:\n",
        "    mean = raw_scores[col].mean()\n",
        "    std = raw_scores[col].std(ddof=0)  # population std\n",
        "    standardized_scores[col] = (raw_scores[col] - mean) / std\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 3) standardized DataFrame\n",
        "# -------------------------------------------------------\n",
        "standardized_scores.columns = ['overlap_z', 'tech_z', 'market_z']\n",
        "\n",
        "print(\"[raw sum]:\\n\", raw_scores)\n",
        "print(\"\\n[standardized score]:\\n\", standardized_scores)\n"
      ],
      "metadata": {
        "id": "_QkCe4uBzhs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adjustText\n",
        "import matplotlib.pyplot as plt\n",
        "from adjustText import adjust_text\n",
        "\n",
        "# X = overlap_z, Y = tech_z\n",
        "x = standardized_scores['overlap_z']\n",
        "y = standardized_scores['tech_z']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.scatter(x, y, color='skyblue', edgecolor='k')\n",
        "\n",
        "texts = []\n",
        "for idx in standardized_scores.index:\n",
        "    plt_x = standardized_scores.loc[idx, 'overlap_z']\n",
        "    plt_y = standardized_scores.loc[idx, 'tech_z']\n",
        "    texts.append(plt.text(plt_x, plt_y, idx, fontsize=9))\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
        "\n",
        "plt.axvline(x=0, color='red', linestyle='--', label='overlap_z = 0')\n",
        "plt.axhline(y=0, color='blue', linestyle='--', label='tech_z = 0')\n",
        "\n",
        "plt.xlabel('Overlap Z-score')\n",
        "plt.ylabel('Tech Z-score')\n",
        "plt.title('Standardized (Z-score) Distribution: Overlap vs Tech')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wAuFib3H0Gyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1_indices = standardized_scores[(standardized_scores['overlap_z'] > 0) & (standardized_scores['tech_z'] > 0)].index\n",
        "# 'V2', 'V3', 'V6', 'V7', 'V12', 'V13', 'V18'\n",
        "\n",
        "q1_keywords = {}\n",
        "\n",
        "softmax.index = standardized_scores.index\n",
        "\n",
        "# q1\n",
        "for idx in q1_indices:\n",
        "    vac = int(idx.replace('V', ''))\n",
        "    threshold = row_stats.loc[vac, '80%']\n",
        "    s = softmax.loc[idx][softmax.loc[idx] >= threshold]\n",
        "    q1_keywords[idx] = s\n",
        "\n",
        "def summarize_keywords_by_domain(keyword_dict):\n",
        "    rows = []\n",
        "    for idx, series in keyword_dict.items():\n",
        "        # divide by domain\n",
        "        overlap_items = sorted(\n",
        "            [(word, prob) for (domain, word), prob in series.items() if domain == 'overlapping'],\n",
        "            key=lambda x: -x[1]\n",
        "        )\n",
        "        tech_items = sorted(\n",
        "            [(word, prob) for (domain, word), prob in series.items() if domain == 'tech'],\n",
        "            key=lambda x: -x[1])\n",
        "\n",
        "        overlap_words = [f\"{word} ({prob:.4f})\" for word, prob in overlap_items]\n",
        "        tech_words = [f\"{word} ({prob:.4f})\" for word, prob in tech_items]\n",
        "\n",
        "        rows.append({\n",
        "            'index': idx,\n",
        "            'overlapping': ' '.join(overlap_words),\n",
        "            'tech': ' '.join(tech_words),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    return df\n",
        "\n",
        "df_q1_clean = summarize_keywords_by_domain(q1_keywords)\n",
        "df_q1_clean_idx = df_q1_clean.set_index('index')\n",
        "\n",
        "df_q1_clean_idx.to_csv('q1q4_keywords_idx.csv', index=False)\n",
        "display(df_q1_clean)"
      ],
      "metadata": {
        "id": "Fp0_3cSd0e4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}